% !TeX root = ../thuthesis-example.tex

\begin{translation}
\label{cha:translation}

\title{面向软件工程的大型语言模型：综述与开放问题\\(Large Language Models for Software Engineering: Survey and Open Problems)}
\maketitle

\tableofcontents


\section{摘要}
本文综述了近年来出现的面向软件工程（SE）的大型语言模型（LLMs）。它还为LLMs应用于软件工程师面临的技术问题提出了开放的研究挑战。LLMs的新特性为软件工程活动带来了新颖性和创造性，包括编码、设计、需求、修复、重构、性能改进、文档和分析。然而，这些相同的新特性也带来了重大的技术挑战；我们需要可靠的技术来排除不正确的解决方案，例如幻觉。调查揭示了混合技术（传统SE + llm）在开发和部署可靠、高效和有效的基于llm的SE中必须发挥的关键作用。

\section{简介}
本文综述了基于LLM的SE的最新发展、进展和实证结果；大型语言模型（LLMs）在软件工程（SE）应用中的应用。我们利用这项调查来强调这一迅速发展但仍处于萌芽状态的研究文献中的差距。基于文献和技术机会的差距，确定了软件工程研究界的开放问题和挑战。

虽然对这样一个快速扩展的领域的任何调查都不能期望或声称是全面的，但我们希望这项调查将提供一个有用的和相对完整的早期宇宙的软件工程这个令人兴奋的新分支学科：基于LLM的软件工程。虽然该领域的科学和技术结构仍在发展中，但已经能够确定未来研究的趋势、生产性途径和需要解决的重要技术挑战。

特别是，我们已经能够识别与软件工程中现有趋势和完善的方法和子学科的重要联系（并与之产生共鸣）。此外，尽管我们找到了相当多的乐观的理由，仍然存在着重要的技术挑战，这些挑战可能会在未来几年影响研究议程。许多作者强调，科学和轶事，幻觉是一个普遍的问题，LLM [1]，也为基于LLM的SE [2]提出了具体的问题。与人类智能一样，幻觉意味着LLM可以创造虚构的输出。在软件工程的环境中，这意味着工程制品可能是不正确的，但看起来是合理的；LLM可能会引入bug。

然而，与LLM的许多其他应用不同，软件工程师通常拥有可自动化的基本事实（软件执行），可以根据这些事实评估大多数软件工程制品。此外，软件工程研究社区已经投入了大量时间来生成自动化和半自动化技术，以检查人类产生的潜在错误结果。这意味着，对于学科和研究界来说，在应对幻觉等问题带来的挑战时，有大量的经验和专业知识可供借鉴。

显然，自动化测试技术 [3]–[5]将在确保正确性方面发挥核心作用，就像它们已经为人类工程的工件所做的那样。当生成全新的特性和系统时，自动化测试数据生成会受到缺乏的影响——一个可自动化的oracle [6]（一种自动技术，用于确定给定输入刺激的输出行为是否正确）。鉴于LLM的幻觉倾向，Oracle问题将保持高度相关性，它的解决方案将变得更加有影响力 [7]。

然而，一些社会工程应用涉及对现有软件系统的改造、改进和开发，为此有一个现成的自动化预言：原始系统的功能行为。在本文中，我们称其为“自动回归Oracle”，这是一种在遗传改良领域已被证明具有优势的方法 [8]。自动回归Oracle只是使用软件系统的现有版本作为基准，对任何后续调整和更改的输出进行基准测试。

当然，存在“烘焙”函数错误的风险，因为自动回归Oracle不能检测系统应该做什么，而只能捕获它当前做什么。因此，自动化回归Oracle只能测试功能回归，因此，它最适合于需要维护现有功能的用例。例如，用于非功能的改进，如性能优化和保留语义的重构。

提供给LLM的输入自然会成为不断增长的研究的重点，我们可以期待关于Prompt Engineering和Prompt Optimisation的文献的快速发展 [9]。本文强调了在软件工程的几个特定方面，Prompt Engineering的现有工作和开放挑战。

LLM的输出不需要仅仅局限于代码，还可以包括其他软件工程制品，如需求、测试用例、设计图表和文档。一般来说，LLM基于语言的性质允许它生成任何语言定义的软件工程制品。

我们通常认为软件工程人工制品是LLM的主要输出，但它不是唯一的输出。初级输出提供的解释也是任何LLM的重要输出。本文综述强调了需要进行更多研究，不仅要优化Prompt Engineering（关注于LLM的输入），还需要对初级输出提供的解释进行优化。

LLM本质上是不确定性的：相同的提示在不同的推理执行上产生不同的答案（除非温度设置为零，在多次执行中通常被发现是次优的） [10]。此外，无论温度设置如何，提示中的细微变化都可能导致非常不同的输出 [10]。以及激励“提示工程”和输出处理，这种不确定性行为为基于LLM的软件工程的科学评估提出了挑战：
\begin{itemize}
    \item 如果每次运行过程的结果都可能不同，我们如何确定所提出的技术是否比最先进的技术取得了进步？
\end{itemize}

这个问题已经在经验软件工程 [11] 和基于搜索的软件工程（SBSE） [12] 的背景下得到了很好的研究。特别是，SBSE与基于LLM的软件工程有许多相似之处，它们都需要在存在噪声、不确定和不完整结果的情况下实现鲁棒的科学评估 [13], [14]。因此，已经有了关于健壮的科学评估技术的成熟的软件工程文献需要迎合基于LLM的科学评估。

例如，经过充分研究的技术，如参数和非参数推断统计，现在通常用于在SBSE学科中存在高度不确定性算法的情况下提供可靠的科学结论。

为了了解基于LLM的软件工程的增长趋势，我们对arXiv中特定主题的出版物数量进行了人工分析。表I包含原始数据 [15]，这些数据是从Kaggle（https://www.kaggle.com/datasets/Cornell-University/arxiv）公开的arXiv元数据转储中手动提取的，可在2023年7月27日访问。我们首先过滤掉了分类代码不以CS前缀开头的出版物（即计算机科学），结果为A列。

识别与LLM相关的计算机科学论文，我们将出版物筛选为子类别人工智能（CS.AI）、机器学习（CS.LG）、神经与进化计算（CS.NE）、软件工程（CS.SE）和编程语言（CS.PL）使用标题或摘要中的查询“大型语言模型”、“LLM”和“GPT”（我们手动排除了过多的缩写实例，如通用规划工具的GPT），结果列L。最后，使用相同的查询来识别软件工程（CS.SE）和编程语言（CS.PL）中基于LLM的软件工程论文。这些查询本质上是近似的，因此我们只局限于基于有强有力证据的总体趋势的结论，而不是观察到的数字的具体细节。然而，我们报告了观察到的原始数字，以支持其他人的复制。

由于这种增长，我们可以期待许多基于LLM的SE的其他调查。文献的快速扩展使得进一步全面的全社会研究不太可能适应一篇论文的空间限制，但我们可以期待许多感兴趣的子领域的具体全面调查，以及系统文献综述（SLRs），通过在系统综述中提出主要文献的具体研究问题来解决全社会的横切问题。这种SLR已经出现了。例如，Hou等人 [16] 最近提供了一份优秀的SLR，涵盖了2017年至2023年229篇研究论文，报告了所解决的SE任务、数据收集和预处理技术以及优化LLM性能的策略（如Prompt Engineering）。

本文的其余部分按照顶层软件开发活动和研究领域进行组织，如图1所示。

\section{开场白}

\subsection{大型语言模型}

大型语言模型（LLM）是指在大量数据上训练过的人工智能（AI）模型，能够以类似人类的方式生成文本。表 III 提供了一个 LLM 术语表，使论文自成一体。

LLM 通常基于深度学习技术，如 Transformer，并有能力生成有用的语言输出。因此，人们发现它们能够执行广泛的语言相关任务，包括文本生成 [16]、回答问题 [17]、翻译 [18]、摘要 [19] 和情感分析 [20]。

Rumelhart 等人 [21] 引入了循环神经网络（RNN）的概念，开辟了处理序列数据的可能性。长短期记忆（LSTM）架构是 Hochreiter 和 Schmidhuber 提出的 RNN 架构的扩展 [22]，显著提高了它们在许多应用中的性能。

2017 年，Vaswani 等人 [23] 介绍了 Transformer 架构，该架构通过自注意力机制捕获单词关系。Transformer 架构对语言建模产生了深远的影响，并引发了 LLM 领域的激增。

2018 年，OpenAI 发布了生成式预训练 Transformer（GPT）模型，随后进行了后续迭代（GPT-2、GPT-3、GPT-3.5 和 GPT-4）。对于 GPT-3 和 3.5，许多观察者注意到生成性能的显著变化，从而吸引了人们对 GPT（特别是 ChatGPT）以及更广泛的 LLM 的极大兴趣。

LLM 能够达到这种性能，部分原因是它们训练的语料库很大。例如，GPT-3 是在 45TB 的文本数据上训练的，有 1750 亿个参数。Meta 在 2023 年 2 月推出了开源的 LLaMA，它在 1.4 万亿个 token 上进行训练，各种模型大小从 70 亿到 650 亿参数 [24]。

\subsection{大型语言模型的类别}

大型语言模型通常可分为三类：
\begin{enumerate}
    \item \textbf{纯编码器模型}：也称为自编码器，由编码器网络组成，但没有单独的解码器网络。它接收一个输入序列并将其映射到低维表示。自动编码器的目的是学习输入数据的编码。纯编码器的 LLM 示例有谷歌的 BERT、Meta 的 RoBERTa 和 Microsoft 的 DeBERTa [1]。
    
    \item \textbf{编码器-解码器模型}：除了编码器网络之外，还有一个解码器网络，它通过基于上下文向量和之前生成的 token 迭代地生成 token 或符号来生成输出序列。它可以用于机器翻译或文本生成等任务。编码器-解码器 LLM 的例子是谷歌的 T5 和 Meta 的 BART [1]。
    
    \item \textbf{仅解码器模型}：与前两种类型的 LLM 不同，仅解码器 LLM 没有处理输入数据的编码器组件，而只有一个解码器组件，该组件直接根据给定的上下文或输入生成输出序列。纯解码器模型通常基于自回归模型等架构，其中输出是逐 token 生成的。解码器生成的每个 token 都以之前生成的 token 和上下文为条件。纯解码器模型的流行示例是 OpenAI 的 GPT 系列（如 GPT-3、GPT-4）、Meta 的 LLaMA、Anthropic 的 Claude 和谷歌的 PaLM [1]。
\end{enumerate}

\subsection{面向软件工程的大型语言模型}

虽然 LLM 已被广泛应用于涉及自然语言的任务，它们在软件开发任务中的应用，包括编程语言，最近也引起了极大的关注。

2021 年，OpenAI 推出了 CodeX，这是 GPT-3 的一个经过微调的后代。CodeX 被 GitHub 的 Copilot 使用，它为用户提供 Visual Studio Code、Visual Studio、Neovim 和 JetBrains 的代码补全。Copilot 的新版本 GitHub Copilot X [2] 是基于 GPT-4 的。2023 年 2 月，GitHub 报告称，平均 46\% [3] 的开发人员的代码是由 Copilot 编写的。仅对 Java 而言，这个数字是 62\%。GitHub 的首席执行官 Thomas Dohmke 预测 Copilot 将在 2023 年 6 月编写 80\% 的代码 [4]。

在 2022 年，DeepMind 引入了 AlphaCode [5]，使用 40B 参数进行训练选定的公共 GitHub 仓库。在有 5000 多名参与者参加的模拟评估中，它平均排名前 54\%。

最新的 GPT 模型 GPT-4 也执行代码生成。根据 GPT-4 的技术报告 [6]，使用 GPT-4 在 HumanEval 上的零样本 pass@1 准确率为 67\%，HumanEval 是 OpenAI 的一个开源数据集，由 164 个编程问题组成。

在 100 个 LeetCode 问题的基准测试中，GPT-4 的性能与人类开发人员相当 [7]。在 2023 年 8 月 24 日，Meta 发布了开源代码 LLaMA [8]，这是公开可用的 LLM 在编码任务上的最新技术。

表 II 列出了为基于自然语言描述的代码生成/完成而设计的代表性 LLM。

\section{需求工程与设计}

需求工程是软件工程中的一门重要学科。它形成了软件工程师所构建的系统的技术属性与构建系统的目的之间的基本联系。有一个成熟的文献和一个大型的研究社区专门关注与需求工程问题相关的问题 [31]。

以前也有关于人工智能方法的工作来支持需求工程，特别是以计算搜索需求工程的形式 [32]。然而，迄今为止，基于 LLM 的软件工程的新兴文献对需求工程学科的关注较少。

Zhang 等人 [33] 对 ChatGPT 在四个数据集上的两个需求分析任务上的零样本需求检索性能进行了初步评估。尽管这些结果只是初步的，但它们提供了乐观的看法，即 LLM 可以用作高效和有效的需求工程的支持。罗等人 [34] 利用 BERT 进行 Prompt Engineering，实现需求的自动分类。Luitel 等人 [35] 专注于需求的完整性，并使用 BERT 生成填补需求中被掩盖的位置的预测。

\subsection{需求工程 LLMs 中的开放问题}

与其他软件开发活动不同，我们没有在基于 LLM 的需求工程或基于 LLM 的设计方面找到太多工作。事实上，甚至有证据表明，实践中的工程师不愿意依靠 LLM 来实现更高层次的设计目标 [36]。因此，有一个很好的机会来扩展这个开放的研究领域。

大多数 LLM 应用程序专注于代码生成、测试和修复等任务。这些任务受益于 LLM 生成代码的能力。然而，LLM 也有很大的支持潜力需求工程活动，得益于其自然语言处理能力。

例如，可追溯性是一个长期存在的，交叉的关注软件工程。特别是，识别需求之间的可追溯性链接而其他工程人工制品，如代码和测试，尤其具有挑战性，因为需求通常是用自然语言编写的语言；天生适合 LLM。

\section{代码生成和补全}

LLMs 的所有软件工程应用领域，代码补全是迄今为止探索得最彻底的领域。甚至在 LLM 出现之前，就有人认为从现有的代码存储库中学习是成功和智能的代码补全的关键 [37]：预训练的 LLM 实现了这些代码补全的早期愿望。

虽然幻觉被认为是 LLM 的弱点，但代码补全的特定任务通过向开发人员提供推荐系统来回避幻觉问题。因此，开发人员有责任在任何幻觉的 LLM 输出泄漏到代码库之前清除它。

当然，高度的幻觉会使代码补全推荐系统无效。代码补全的广泛和快速采用，以及已经报告的积极结果，提供尚未发生这种情况的早期迹象。例如，Murali 等人 [38] 报告了在 Meta 上部署 codecomposition 的经验，codecomposition 是一个基于 Incoder LLM [39] 的代码补全工具。在 15 天的时间里，codecomposition 提出了 450 万条代码补全建议，开发人员的接受率为 22\%。质量反馈是高度积极的，92\% 的人是积极的。类似地，Peng et al. [40] 报告称，与没有获得任何此类支持的对照组相比，程序员在使用 GitHub Copilot 时可以更快地完成一项重要任务（用 JavaScript 实现 HTTP 服务器）56\%。

许多软件工程师似乎已经认定，好处超过任何必要的人工过滤工作，人们的热情程度和采用率已经被报道了。一旦基于 LLM 的代码完成被完全采用，人们期望程序员将花费更多的时间审查而不是编写代码 [41]。

\subsection{代码生成模型}

自动代码生成有着悠久的历史，它的起源可以追溯到自动程序合成的早期愿景 [42]，这些愿景一直在继续发展并产生了令人印象深刻的结果 [43]。

来自 Hindle 等人关于软件自然性的开创性工作 [44]，我们知道程序员编写代码（和语言强制代码编写风格），使代码高度可预测。此外，Barr 等人 [45] 发现对大型 Java 项目仓库的提交有 43\% 可以从现有代码中重构。他们将其称为“整形手术假说”，因为自动修复是通过清除现有代码来修补其他地方的问题 [46]。

他们的实证研究为这种清除方法的有效性提供了证据，但也强调了软件的重复性和可预测性。在更大的存储库（sourceforge）中，Gabel 和 Su [47] 发现一个程序员必须要写超过六行代码才能创建一个新颖的代码片段。

这些关于代码自然性、可重用性和可预测性的研究发现，使 LLM 能够做到这一点并不奇怪，利用相同的可预测重用性来为代码生成提供有效的建议。这些观察结果支持了修复和遗传改良的“生成-测试”方法的增长 [8], [46]。生成-测试方法提供了更大的代码转换自由（与更传统的通过构造来纠正的方法相比 [48]），这正是因为生成的代码可能无法保持严格的、数学定义的（并不总是适当的，也不是有用的）对正确性的解释。

这种探索“语义近邻”更广阔空间的自由，允许基因改进找到戏剧性的优化（见 VI-C 节）。遗传改进方法、命名法和评估方法还提供了一个科学框架，用于理解和评估基于 LLM 的代码生成。两种技术分享程序转换和代码生成的“生成-测试”方法，有可能使许多现有的基因改良工作直接适用到基于 LLM 的代码生成。

2021 年，Chen 等人 [49] 介绍了 CodeX，一个在 GitHub 公开代码上进行微调的 GPT 语言模型，并评估了它的 Python 代码编写能力。他们发布了一个名为 ‘HumanEval’ 的新评估集，以衡量从文档字符串合成程序的功能正确性，并发现 CodeX 在解决这些问题时表现优于 GPT-3 和 GPT-J。从那时起，关于基于 LLM 的代码生成的研究呈爆炸式增长，HumanEval 数据集已被用于许多后续研究。

在 2022 年，Li 等人 [27] 引入了 AlphaCode，这是一个用于代码生成的系统，为竞争性编程问题创造了新的解决方案。他们发现有三个关键组件对于实现可靠的性能至关重要：
\begin{enumerate}
    \item 用于训练和评估的广泛编程数据集。
    \item 大型且高效采样的基于 Transformer 的架构。
    \item 大规模模型采样以探索搜索空间，然后是基于行为的过滤。
\end{enumerate}

在 Codeforces 平台上编程比赛的模拟评估中，AlphaCode 在超过 5000 名参与者的比赛中平均取得了前 54\% 的排名。

几篇论文还介绍了代码合成 LLMs [50]–[53]，基于很少对训练数据进行预过滤的大型数据集。然而，在 2023 年，Gunasekar 等人 [54] 报告称，通过仅使用教科书质量的代码语料库进行训练，具有较低参数数量的 LLM 可以实现与大得多的模型相当的性能。

他们使用 GPT-4 模型对现有的 Python 代码语料库进行分类，促使它确定给定代码对想要学习编程的学生的教育价值。其次，他们使用 GPT-3.5 创建关于 Python 的合成教科书。特定的代码生成用例也已经被解决，例如数值算法代码生成 [55]，以及从行为描述生成代码 [56]。现有 LLM 用于代码生成和代码生成排行榜的更多示例可以在表 II 和图 4 中找到。
\subsection{改进的Prompt工程代码生成}

提示工程被广泛用作改进代码生成的一种方法。例如，Li等人 [57] 报道 Pass@1 改进了大约 50\% 到 80\% CodeX、CodeGeeX、CodeGen 和 InCoder 的几个基准测试（Python 的 MBPP、Java 的 MBJP 和 JavaScript 的 MBJSP）。Döderlein 等人 [58] 报告了 Copilot 和 CodeX 在 HumanEval 和 LeetCode 上的成功率从大约 1/4 到 3/4 的快速工程改进。他和 Vechev [59] 使用 Prompt Engineering 来提高 LLM 生成代码的安全性，安全性从 59\%（考虑的情况）提高到 92\%。White 等人 [60] 为各种软件工程任务（包括代码生成）提供了提示工程设计模式的目录。Denny 等人 [61] 认为，Prompt Engineering 是一种有用的学习活动，可以培养软件工程学生的计算思维。

其他作者考虑了将提示工程分解为与 LLM 迭代和多阶段对话的方法，使其更接近思维链推理。例如，Li 等人 [62], [63] 报告说，使用两阶段基于草图的方法，即 SkCoder，LLM 首先创建草图，然后随后实现这些草图，ChatGPT Pass@1 增加了 18\%。Jiang 等人 [64] 和 Zhang 等人 [65] 也试图通过促使 LLM 反思和自我编辑来部署思维链式的推理。

现有的软件工程分析技术还可以为微调和提示工程提供额外的信息。例如，Ahmed 等人 [66] 展示了如何在提示中使用简单的静态分析，以通过少样本学习提高代码生成的性能。

Shin 等 [67] 比较对代码生成任务使用 GPT-4 进行提示工程和微调，表明微调比提示工程工作得更好。

\subsection{LLM 和其他技术的混合体}

通过对文献的调查，我们发现了强有力的证据，一些最有希望的结果可以通过混合实现；将 LLMs 与其他现有的软件工程技术相结合。本节概述用于代码生成的混合 LLM 工作。

一些作者开发了 LLM 与规划和搜索相结合的混合体。例如，Zhang et al. [68], [69] 报告称，与基线相比，性能提高了约 11\% 到 27\% Zhang et al. [70] 使用 API 搜索技术的混合代码生成。

混合方法也有使用现有的软件工程和/或人工智能技术从 LLM 的 top-n 输出中选择最佳候选。例如，Chen 等人 [71] 使用测试生成来选择候选者，并报告了大约 20\% 的改进 5 个预训练的 LLM；Inala 等人 [72] 使用基于神经网络的排序器预测代码的正确性和潜在的错误。Jain 等人 [73] 提出了 Jigsaw，基于对生成的代码进行后处理程序分析与综合技术。

Dong 等人 [74] 将 LLM 视为代理，让多个 LLM 在协作和交互式地处理代码生成任务方面发挥着不同的作用。他们报告了大约 30\%-47\% 的改善。

\subsection{基于 LLM 的代码生成的科学评估}

迫切需要进行更彻底的科学评估。许多作者都曾报道过 LLM 无法生成正确、安全和可靠代码的案例。Poldrack 等人 [75] 也强调了大量人工验证的必要性。在本节中，我们从正确性方面综述了基于 LLM 的代码生成的经验评估的文献，稳健性，可解释性，决定论，以及安全。

\subsubsection{正确性评估} GPT-4 技术报告 [28] 上评估了 GPT-4 代码生成的正确性 HumanEval 数据集的零样本准确率为 67\%，略有提高 Yetistiren 等人报道的（早期 ChatGPT）结果 [76]。

Borji [77] 对 ChatGPT 的 LLM 代码生成失败进行了严格、分类和系统的分析。在他们的工作中，介绍和讨论了 11 类失败，包括推理、事实错误、数学、编码和偏差。

图 4 根据 Papers With Code（一个突出 AI 研究趋势以及方法和模型背后的代码的平台），显示了在 HumanEval 数据集上 Pass@1（即 Top-1 代码候选的测试通过率）代码生成正确性的排行榜。每个方法背后的 LLM 模型都显示在括号中。在撰写本文时，最佳的代码生成模型 Reflexion [78] 可以为 90\% 以上的生成任务生成正确的代码。然而，在这样一个快速发展的领域中，这些数字和不同语言模型的相对排名必然会发生变化。例如，原始 GPT-4 报告 [28] 中给出的 HumanEval 上正确代码的数字仅为 67\%，因此更新后的数字为 80\%（写作本书时，也就是 5 个月后）。

从 Papers-With-Code 网站检索到的数据大概代表了 GPT-4 自那时以来的演变。尽管在代码生成和补全的文献中有很好的结果，Din 等人 [79] 报告称，当上下文包含 bug 时，HumanEval 的代码补全性能下降了 50\% 以上。

\subsubsection{鲁棒性评估} LLM 代码生成的鲁棒性是相似的提示引起语义和语法相似的代码生成的程度。Treude [80] 介绍了 GPTCOMPARE，一个原型工具，用于视觉上突出 LLM 代码输出之间的相似性和差异性。Yan 等人 [81] 引入 COCO 来测试基于 LLM 的代码生成系统的健壮性和一致性。

\subsubsection{可解释性评估} 与之前的机器学习技术相比，LLM 的一个相当大的优势是代码生成工件伴随着解释的方式。通过提供额外的信心和更快的理解，这些解释有可能增加采用率。需要更多的工作来评估和优化伴随生成的代码和其他软件工程工件的解释。

MacNeil 等人的初步评估 [82] 在他们的交互式 Web 开发电子书上，表明大多数学生认为 LLM 生成的代码解释是有帮助的。Noever 和 Williams [83] 还展示了解释的潜力，以帮助人类工程师，特别是在代码混淆或缺乏足够的现有文档的情况下。通过这种方式，产生洞察力和解释的能力可能不仅仅是证明 LLM 本身生成的代码，而是可能成为有价值的教育和文档来源（见 XI 部分）。

Sun 等人 [84] 关注了用户对生成式 AI 在三个软件工程用例中的可解释性需求：基于自然语言描述的代码生成（使用 Copilot），不同编程语言之间的翻译（使用 Transcoder），以及代码自动补全（使用 Copilot）。他们的调查是由 43 名软件工程师参加的 9 个研讨会进行的，并确定了在生成式人工智能（GenAI）背景下对代码的可解释性需求的 11 类。

\subsubsection{决定论评价}

LLM 是不确定性的。欧阳等人 [10] 对 ChatGPT 在代码生成中的不确定性进行了实证研究，发现超过 60\% 的任务在不同的请求中没有相同的测试输出。然而，他们对文献的研究表明，在基于 LLM 的代码生成研究中，只有 21.1\% 的论文在实验中考虑了不确定性威胁。

\subsubsection{安全评估}

Hajipour 等人 [86] 提出了一种小样本提示的方法来检测安全漏洞，报告称他们的方法在几个模型中自动发现了数千个安全漏洞。Khoury 等人 [87] 发现 ChatGPT 生成的代码经常远远低于安全编码的最低标准。Rise 和 Bőhme [88] 报告的结果表明，由于模型对不相关的训练集特征过拟合，漏洞检测精度可能被过度报告。

此外，Yetistiren 等人 [76] 对其性能进行了综合评价，包括 Copilot、CodeWhisperer 和 ChatGPT，涵盖不同方面包括代码有效性、代码正确性、代码安全性和代码可靠性。他们的结果显示，在表现上有很大程度的差异，激发了进一步研究和调查的需要。例如，他们发现 65\%、46\% 和 31\% 的程序分别由 ChatGPT、Copilot 和 CodeWhisperer 生成是正确的。

\subsubsection{基准测试}

与其他科学评估一样，软件工程评估依赖于公开可用且具有代表性的基准套件。其中一些已经出现，可以支持基于 LLM 的应用程序的软件工程评估。带代码的论文平台 [5] 提供了 15 个用于评估代码生成的基准的摘要。

评估通常依赖于编程课程 [89] 中的小编程问题、综合生成的问题集 [90]，以及 LeetCode [29], [65], [91] 等在线评判平台。尽管在训练集上不同的 LLM 报告的结果自然不同，但这些评估的总体结论表明，成功率在 20\% 到 80\% 之间。

然而，现有的代码生成基准往往依赖于测试套件来自动判断代码的正确性，这可能不够充分，导致错误判断 [92]。这突出表明需要对评估基准进行更多工作，以专门为基于 LLM 的代码生成评估量身定制。Liu 等人 [93] 引起了对这个问题的关注，展示了现有的测试套件如何导致高程度的假阳性结论（对于在线评判平台 [92] 也是一个严重的问题）。为了缓解这个问题，他们提出了 EvalPlus —— 一个代码合成基准框架，可以自动生成测试输入，并严格评估 LLM 生成代码的功能正确性。他们对 14 个流行的 LLM（包括 GPT-4 和 ChatGPT）的评估表明，使用为 HumanEval 新生成的测试，Pass@k 的评估在考虑的问题上平均下降了 15\%。

Jimenez 等人 [94] 介绍了 SW-Bench，目的是在现实的软件工程环境中评估 LLM 的代码生成问题。SW-Bench 包含 2294 个软件工程问题，来自真实的 GitHub 问题。实验结果表明，Claude 2 和 GPT-4 分别只解决了 4.8\% 和 1.7\% 的编码任务。

\subsection{代码生成和补全中的开放性问题}

评估生成的代码仍然是基于 LLM 的代码生成和补全的关键问题。虽然许多工作已经开始将现有的软件测试知识应用于此问题，但我们希望自动化测试技术与代码生成和补全技术更紧密地集成。

幸运的是，有大量关于自动化测试数据生成的现有工作 [3]–[5]，其中许多工作将在确保 LLM 生成的工程工件的正确性方面发挥重要作用。本文中涉及的挑战的一个反复出现的主题是，代码执行精确地提供了过滤幻觉响应所需的“基本事实”。它还可以作为交互推理/行动（‘ReAct’）对话 [95] 的一部分，在 LLM 之间和内部提供指导。

自动化的测试数据生成允许软件工程师以探索运行时基本事实的最相关区域为目标。这种基于测试的目标可以帮助过滤、微调和优化提示，从而将幻觉带来的问题最小化。LLM 在自动化构建有效和高效的软件测试套件的过程中也具有相当大的潜力。

另一个重要问题是如何有效地微调预训练的 LLM，以便它们对特定的编程语言、代码库或领域表现更好。这一点尤其重要，因为从头开始训练 LLM 需要大量的计算资源。例如，当特定编程语言的训练示例数量不足时，迁移学习被提出作为一种提高代码补全性能的方法 [96]。

目前的研究重点是由 LLM 产生的代码。然而，LLM 产生的解释可能至少同样重要。人们可以想象，在许多情况下，工程师宁愿接受一个（可能）带有令人信服的解释的次优软件工程工件，而不是一个具有不那么令人信服的解释的潜在性能更高的解决方案。毕竟，工程师经常对人类设计的工程工件做出相同的判断，那么我们为什么会期望机器生产的产品有任何不同呢？与专注于优化 LLM 输入的 Prompt Engineering 一样，**解释工程** 本身也可能成为一个研究领域。

\section{软件测试}

软件测试是一门成熟的研究学科可以追溯到图灵在20世纪40年代末的开创性工作[97]。这项研究的重点主要集中在测试套件的自动生成上，能够以较低的计算成本实现高错误揭示潜力[3]–[5]。这不仅为我们提供了能够淘汰不正确的llm生成代码的技术，而且还为我们提供了一个成熟的基线，用于比较新的基于llm和混合的测试套件生成技术。

已经有足够多的工作需要对基于llm的软件测试进行调查：Wang等人[98]介绍了以测试为主，但也包括调试和修复的论文综述。他们报告了52篇论文（33篇自2022年以来发表），其中大约三分之一涉及基于测试的LLM微调，而其余的依赖于快速工程。

\subsection{使用llm生成新测试}

在本节中，回顾了用于测试数据生成的llm的现有工作，然后强调了这一新兴领域发展的开放问题和挑战。生成的测试可能无法执行，因为LLM不保证生成可编译的代码。Nie等人[99]报告使用TeCo生成的29％的测试是可执行的，同时Yuan等人[100]发现，大约四分之一的测试由ChatGPT生成是可执行的，在适当的提示工程下上升到三分之一。

在那些能够编译的测试中，一些作者报告了所实现的代码覆盖率。例如，Barei ß等[101]报告说，从10％的使用实现了增长Randoop[102]到14％与CodeX。Hashtroudi et al.[103]报告说，通过微调代码5生成的测试代码的行覆盖率增加了50％。Siddiq等人[104]报道80％的覆盖率使用CodeX的HumanEval数据集，但也发现没有被研究的llm能够在EvoSuite SF110数据集上达到2％以上的覆盖率。

将现有的测试生成和评估技术（如基于模糊测试和基于搜索的测试）与llm相结合的混合方法已经显示出良好的效果。例如，Lemieux等人[105]介绍了CODAMOSA，一种结合基于搜索的软件测试（Search-Based Software Testing，SBST）[5]和CodeX的算法，为被测程序生成高覆盖率的测试用例。当SBST的覆盖率改进停滞时，CODAMOSA要求CodeX为未覆盖的功能提供示例测试用例。这有助于SBST将其搜索重定向到搜索空间中更有用的区域。在对486个基准的评估中，CODAMOSA实现了比仅SBST和llm基线更高的覆盖率。

Hu等人[106]引入了ChatFuzz，它用ChatGPT对AFL进行了扩充，以获得更多符合格式的变异体。在三个基准测试程序中选取12个目标程序进行测试，ChatFuzz的分支覆盖率比AFL高出13％。Dakhel等人[107]使用变异测试来帮助llm生成测试。特别是，他们增强Codex和llama-2聊天提示与幸存的变种人。他们报告说，他们的方法检测到的人为错误高出28％。

Xia等人[108]最近证明，LLMs可以作为跨不同应用程序域和编程语言的系统的通用模糊器，包括C/C++编译器，JDK，SMT求解器，甚至是量子计算系统。Deng等人[109]提出了TitanFuzz，它使用LLMs（即Codex）来生成有效的输入DL程序来测试DL库。在PyTorch和TensorFlow上的结果表明，TitanFuzz可以实现代码覆盖率比最先进的模糊测试器高30％/51％。后来，他们进一步引入了FuzzGPT[110]，它可以综合不寻常的程序来对DL库进行模糊测试。他们的结果表明，当重新针对基于模糊测试时，CodeX和CodeGen在PyTorch和TensorFlow上的性能优于TitanFuzz。

Li等人[111]使用了差分测试和ChatGPT的混合，为了提高后者对缺陷程序生成诱发失效的测试用例的能力。他们报告说测试效率从29％提高到78％。

基于llm的测试生成的一个有前途的领域是GUI测试，因为通过GUI操纵应用程序状态通常需要对用户界面和应用领域。Sun等[112]通过文本描述用户界面，并询问ChatGPT根据文本下一步想执行什么操作，然后将答案转换为实际的GUI交互。相比之下，活动覆盖率提高了32％到最先进的水平。

对于经典技术来说，一个特别重要且具有挑战性的问题是从用户报告中构造测试用例。用户报告是用自然语言编写的。这对现有技术提出了相当大的挑战，但非常适合llm。Kang等人[113]介绍了Libro，一种自动生成测试的少样本学习失败再现技术，基于CodeX的通用bug报告。天秤座成功复制大约三分之一的失败。

Feng和Chen[114]使用带链的LLM开箱即用（ChatGPT），通过自然语言定义的重现步骤，证明了在bug报告上的重现率为80％，思想本身就能促进工程。

一些作者考虑使用提示工程来改善测试生成的结果[115], [116]。例如，Schafer等人[116]提出了TESTPILOT，它重新提示失败的测试和相关的错误消息，实现报告平均报表覆盖率为68％。Xie等[117]为测试生成创建提示解析项目并创建包含焦点方法及其依赖关系的自适应焦点上下文。他们进一步使用基于规则的修复来修复测试中的语法和简单编译错误。

尽管基于llm的测试结果可能不确定，研究人员已经探索了基于“自一致性”概念的交叉参考或多数投票[118], [119]方法来估计llm的置信度[120]。例如，Kang等人介绍的Libro[113]使用CodeX从可以重现故障的bug报告中生成测试。如果多个测试显示类似的失败行为，Libro估计LLM对其预测是“有信心的”。此外，当存在部分oracle信息时，这也可以用于增强置信度估计。当整个过程的目标是改进现有代码时，这种部分oracle信息通常是可用的。例如，当提高现有测试的效率时，可以通过观察测试是否与原始测试行为相似（相同情况下是否通过）来收集自动化的部分oracle信息，并且执行速度也更快。

\subsection{测试充分性评估}

测试有效性通常根据“充分性标准”来衡量[121], [122]。由于测试不能穷尽地探索每一种可能性，充分性标准提供了一套测试所达到的有效性的下限形式。变异测试是一种被广泛研究的评估软件测试套件充分性的技术[123], [124]，其中故意注入合成错误（称为“变异体”）以评估测试充分性。变异测试已经被证明可以提供比其他基于结构覆盖的标准（如语句覆盖和分支覆盖[125]）更严格的充分性标准。

变异测试中一个具有挑战性的开放问题是生成忠实地模拟现实世界中重要类别错误的变异体。Khanfir等人[126]使用CodeBert生成类似开发者的突变体，发现他们的方法比PiTest具有更好的错误揭示能力。Garg等人[127]应用CodeBERT来生成能够忠实捕获漏洞的突变体。他们评估发现17％的突变体没有通过测试，而这些测试分别被89％的漏洞通过。Brownlee[128]使用GPT-3.5生成用于遗传改进的突变体，并观察到基于llm的随机抽样编辑更容易编译和通过单元测试通常与标准的GI编辑比较。

\subsection{测试最小化}

测试最小化通过去除冗余的测试用例来提高软件测试的效率。Pan等[129]应用要提取的代码有：CodeBERT、GraphCodeBERT和UniXcoder嵌入测试代码以进行测试最小化。他们的方法达到了0.84的错误检测率，并且运行速度比基线快得多（平均26.73分钟）。

\subsection{测试输出预测}

Liu等人[130]提出了CodeExecutor，一种预训练的Transformer模型预测程序的整个执行轨迹。其目的是模仿现实世界中任意程序执行的行为。他们的评估比较了CodeExecutor和CodeX，表明CodeExecutor在执行轨迹预测方面明显优于CodeX（例如，教程数据集的输出精度为76％ vs. 13％）。

\subsection{测试不稳定性}

如果在执行上下文中没有任何明显的（测试人员可控的）变化，测试在某些情况下可以通过，而在其他情况下失败，那么测试就是不稳定的。测试不稳定是目前工业上最紧迫和影响测试效果的问题之一[131]。llm已被用于预测flakiness，准确率很高（报告了73％的F1分数[132], [133]和97％的准确率[134]）。

\subsection{用于软件测试的LLMs中的开放问题}

基于llm的软件测试数据生成存在许多开放性问题，它很好地掌握在现有的软件测试技术之内。因此，我们可以期待在未来几年中，基于llm的软件测试生成将出现令人兴奋的突破。本节概述了本研究议程的一些方向。

\subsubsection{提示工程}

一个好的软件测试有许多方面可以被合适的提示工程（prompt engineering）所优化。例如，我们需要了解如何设计提示：
\begin{itemize}
    \item 预测并减少生成的测试不稳定性；
    \item 揭示可能的故障，例如通过对历史故障数据进行训练；
    \item 优化模拟测试和集成测试之间的平衡；
    \item 制作真实的数据构建器、模拟对象、参数和输入；
    \item 预测哪些测试最有可能引出覆盖边界情况的测试；
    \item 定制测试生成以关注生产中普遍存在的行为。
\end{itemize}

\subsubsection{增加现有的测试}

基于llm的测试生成的工作主要集中在新测试套件的自动生成。然而，考虑到现有的测试生成技术的多样性，仍然存在一个重要的（相对较少研究的）开放问题，即基于现有测试套件的扩充和再生[135], [136]。

测试扩充和再生可以利用小样本学习和/或微调（在现有的测试数据集和历史错误上）来生成扩充的测试套件。llm还需要进行更多的工作，以生成额外的测试断言，利用可用的训练数据来捕获边界情况、历史错误和可能的程序员错误。杂交llm和现有的自动化测试生成技术之间的关系也是一个富有成效的主题[105]。

\subsubsection{测试正确性}

传统的软件测试生成受到Oracle问题的困扰[6]，即，由于缺乏自动化的Oracle来确定测试结果是否正确，它们受到了限制。有两种情况与ai生成的测试有关：
\begin{enumerate}
    \item 生成的测试在当前版本上通过：我们可以假设功能已经被正确地测试过，因此生成的测试作为一个回归测试，可以根据它检查未来的更改。
    \item 生成的测试在当前版本中失败了：我们需要知道断言是错误的，还是生成的测试找到了bug。
\end{enumerate}

这两种情况都可能在缺乏自我调节的情况下产生有害的后果。通过的测试用例可能仅仅反映偶然的正确性[137], [138]。更糟糕的是，代码实际上可能是不正确的（测试同样不正确，但捕获并执行了不正确的行为）。在这种情况下，生成的测试将倾向于阻止错误修复，因为在未来的修复中失败。这个问题也会影响llm生成的测试用例，并且在这些测试产生幻觉的情况下可能更有害，在生成的测试中嵌入这些不正确的Oracle断言。

另一方面，当生成的测试用例失败时，这可能表明存在bug。这个bug的发现将意味着基于llm的测试的“胜利”。然而，如果假阳性比率远高于真正阳性比率，那么该技术的成本（例如，在人工评估中的成本）可能会使其不可行，即使它确实揭示了真正的bug[131]。在置信度的自我评估，对生成的测试的正确性、一致性和健壮性的自我检查方面还需要更多的工作。我们需要开发自动评估、增强，并在向开发人员呈现“测试信号”之前，过滤执行基于llm的测试的原始结果。

\subsubsection{变异测试}

还需要更多的工作来探索基于llm的测试生成的充分性，以及使用基于llm的技术来支持和增强测试充分性的调查和评估。llm可以在故障模型上进行微调，从而用于建议与真实故障高度耦合的变异体，因此可以用于评估测试充分性。

\section{维护、演进和部署}

软件的维护和演化是一个重要的研究课题。它们关注现有的代码库，我们从这些代码库中寻求理解和业务逻辑提取，并为此寻求重新设计、修复和重构。诸如此类的维护问题都属于语言丰富的问题域。因此，正如我们在本节中回顾的那样，这一领域发现了许多基于llm的技术的应用并不令人惊讶。

\subsection{调试}

Kang等人[140]研究了GPT-3.5的错误定位能力，并发现LLM通常可以在第一次尝试时识别出错误的方法。吴等人[141]对GPT-3.5和GPT-4在错误定位精度、稳定性和可解释性方面的能力进行了全面的研究。实验结果表明，GPT-4达到了预期的错误定位精度，但当代码上下文变长时，性能会急剧下降。

Feng和Chen[142]提出了AdbGPT，它通过ChatGPT的提示工程，从缺陷报告中重现Android缺陷。在包含88个缺陷报告的数据集上，AdbGPT能够成功重现81％的缺陷报告，优于基线和消融。Joshi等人[143]专注于多语言调试，提出了RING，一种基于提示的策略，将修复概念化为本地化、转换和候选排序。

为了解决故障定位和程序修复中的数据泄漏威胁，Wu等人[144]引入了与1254个Java bug和1625个Python错误之间的研究，涵盖2021年10月至2023年9月的数据。研究人员可以根据其创建周期选择代码样本，从而评估其有效性，根据不同的llm的训练数据截止日期。此外，也有使用LLMs预测bug严重性的工作[145]。

\subsection{程序修复}

十多年来，在软件工程研究社区[146], [147]中，修复bug一直是一个非常有趣的话题，并且已经在最初的工业部署中找到了方法[148]。

许多关于自动修复的工作使用了在遗传改进领域广泛采用的生成-测试方法，并随时适用于基于llm的技术。因此，llm肯定会对自动化软件修复产生积极影响，但正如我们在本节中报告的那样，在驯服幻觉问题和管理可扩展性方面仍然存在技术挑战。

为了实现可伸缩性，所有的生成和测试方法都需要解决构建时间问题[149]。基于llm的修复也不例外；幻觉的倾向使测试阶段能够定期执行变得更加重要。很可能使用ReAct部署模型[95]将有助于找到高效和有效的工程权衡。当ReAct应用于修复时，整个方法将在‘Reason’阶段（生成候选修复）和‘Action’阶段（通过测试评估修复，这涉及构建问题）之间交替进行。

为了解决这个问题，我们可以参考关于软件修复的成熟文献[46], [150]，这些文献建立在基于搜索的软件工程方法的二十多年发展的基础上[12], [151]。该文献为研究社区提供了坚实的经验和专业知识基础，使其非常适合开发基于llm的生成和测试方法来解决问题。

最近的修复工作已经开始使用神经AI模型，如Tufano等人的开创性工作[152]。最近，自2022年以来，关于基于llm的修复的新兴研究文献得到了快速发展。例如，Xia等人[153]提出了AlphaRepair。它将APR问题重新定义为一个填空（或填充）任务，其中llm可以根据潜在有错误的代码部分的双向上下文直接填充正确的代码。AlphaRepair还首次证明了llm可以超过所有之前的APR技术。

他们进一步对使用三种不同语言的五个数据集的九个llm进行了实证研究[154]。他们的发现不仅肯定了基于llm的APR的优越性（特别是完形风格的方法），而且提供了一些实用的指导方针。Wei等人[155]通过合成一个补丁LLM和Completion引擎之间的交互，并发现该方法超过了表现最好的基线，修复了14和16个bug。

程序修复自然适合prompt工程的对话模型。Xia等人[156]提出conversational APR，以对话的方式在补丁生成和验证之间交替进行。对10个llm的评估表明，该方法在效果和效率上都具有优越性。

他们进一步提出了ChatRepair[157]，对话式方法修复了337个bug中的162个，每个bug的成本仅为0.42美元，因此也解决了所需计算资源的潜在问题。陈等人[158]介绍了自我调试，它教LLM通过少样本学习调试其预测的代码，自调试报告的基线精度提高了12％。

例如，研究也报告了特定种类的修复结果，Pearce等人[159]报告了五个商业llm对安全漏洞的修复结果，Charalambous等人[160]将ChatGPT与形式化验证策略相结合，验证并自动修复软件漏洞。Cao等人[161]报告了ChatGPT对深度学习（DL）程序修复的结果。

修复并不总是从已存在的失败测试用例开始，而可以从生产环境中对失败的自然语言描述开始。自动化打开了对用户生成的bug报告做出更快响应的大门。Fakhoury等人[162]的工作也探索了llm的修复路线，他们从自然语言问题生成了功能正确的代码编辑描述。他们提出了Defects4J-nl2fix，这是一个由283个Java程序组成的数据集，来自具有bug修复的高级描述的Defects4J数据集。最先进的llm对此进行了基准评估，达到了高达21％的Top-1和36％的Top-5精度。

自动化修复还可以减轻工程师的负担，管理生产系统的devops式的随叫随到。例如，Ahmed等人[163]研究了基于llm的微软云服务事件的根本原因和补救。他们使用4万起微软云服务事件数据，应用语义和词汇指标，在零样本、微调和多任务环境下评估了多个llm，表明微调显著提高了事件响应的有效性。

针对特定任务或领域进行微调的能力可以显著提高程序修复中的模型性能。Jiang等人[164]实证评估了10个不同的代码语言模型（CLMs）和4个故障基准的性能，并表明特定于修复的微调可以显著提高成功率。平均而言，10个CLMs已经比最先进的基于DL的APR技术成功修复了72％的故障。经过微调后，该数字增加到160％。

Jin等人[165]提出了InferFix，其中包含一个在监督错误修复数据上进行微调的LLM（Codex Cushman）。InferFix在Java上实现了76％的Top-1修复精度，在C\#上使用InferredBugs数据集达到了65％以上。Berabi等人[166]介绍了TFix，一种对错误修复数据进行微调的T5模型，报告称其性能优于现有的基于学习的方法。Xia等人[167]结合了LLM微调和提示来自动化修复，并证明了他们的方法修复了89个和44个bug（比基线高出15个和8个）。

llm还可以帮助解释它们生成的补丁。Kang等人[168]提出AutoSD，用llm提供调试解释，以帮助开发人员判断补丁的正确性。他们发现AutoSD产生了与现有基线相当的结果，具有高质量的修复解释。Sobania[169]研究了GPT-3.5在解释基于搜索的修复工具ARJA-e对Defects4J中的30个bug生成的补丁，84％的LLM解释被发现是正确的。

\subsection{性能改进}

自从计算机编程诞生以来，性能优化的重要性就已经得到了认可。事实上，Ada Lovelace甚至在她19世纪的分析引擎笔记[170]中提到了性能优化。许多优化的初始实际部署发生在编译器开发中，通过优化编译器[171]。这是当前实用和高效计算的基础，但它必须是一种通用的方法；由于其通用性而广泛适用，但出于同样的原因，对于定制的问题领域不是最优的。因此，也有很多关于具体的源到源转换以提高优化的工作，可以追溯到20世纪70年代[172], [173]。

长期以来，这项工作的重点是寻找合适的保意义变换集，其动机是可以将一个正确的程序转换为一个更高效的版本，同时保持其正确性。然而，最近，程序合成的研究发生了不同的转变：受遗传编程的启发[174]，以及来自早期自动程序修复的研究[146], [175]，它考虑了一种被称为“基因改良”的方法中的更广泛的转变[8], [176]。

更广泛的转换集可能产生不正确的代码，但自动化测试可以过滤这些代码，以确保对预期语义的足够忠实。此外，将现有代码视为一种“遗传物质”的自由，在非功能属性方面产生了巨大的改进，例如执行时间、内存和功耗（例如，一个重要的基因测序系统的70倍加速[177]）。

虽然进化算法等人工智能技术提高性能的潜力已经得到了充分的研究，但研究人员才刚刚开始考虑这种潜力用于基于llm的性能改进。在Madaan等人的工作中[178]，作者使用CODEGEN和CodeX提出功能正确、性能提高的编辑（PIE），提高Python和C++的执行时间（已经使用最大优化编译器选项-O3进行了预优化）。类似地，Garg等人[179]提出DeepDev-PERF，一种针对C\#应用程序的性能改进建议方法。DeepDev-PERF使用英语预训练的BART-large模型，并进一步对源代码进行预训练。Kang和Yoo[180]提出使用llm来建议用于遗传改进的目标特异性变异算子，并提供了提高效率和减少内存消耗的演示。Garg等人[181]提出了RAPGen，它为llm生成零样本提示以提高性能。提示信息是通过从预构建的性能知识库中检索指令生成的。Chen等人[182]使用GPT模型作为他们的源代码优化方法超音速的基线，并发现超音速提高了运行时间26.0％的项目，而GPT-3.5-Turbo仅提高12.0％，GPT-4则仅提高4.0％。

Cummins等人[183]重点研究了编译器的性能，介绍了用于优化编译器指令的LLMs的结果。他们的研究表明，一个相对较小的（7B参数）LLM，经过训练以生成指令计数和优化编译器LLVM代码，可以在减少编译器指令计数方面带来3％的改进，超越最先进的技术。他们的结果在正确性方面也很有希望，91％的代码可编译，70％的功能正确，与原始编译器输出相比有所提升。

在过去50年中，软件工程社区已经发展出如何将现有的软件系统转换为在保留功能行为的同时提高性能的等效系统的概念。在20世纪70年代，最关注的是正确性，因此转换集合被定义为仅由构造上（功能上）正确的转换步骤组成。然而，到2010年，社区已经在探索更宽松的等价概念的应用，这些等价概念仅仅保留了对原始行为足够的操作忠实度。因此，20世纪70年代严格的语义约束得到了相当大的放松，允许转换甚至可能使某些测试用例失败。在同一时期，业务性能变得越来越重要。该研究议程的一个关键基本原则是，当整个软件系统在一个低效率导致剩余资源不足的系统上运行时，没有一个整体软件系统可以被认为是功能正确的。这个原则甚至适用于软件已经完全被证明功能正确的情况（相对少见）。正如更精辟的口号所言：
\begin{quote}
“电池没电是不对的” [8]。
\end{quote}

社区代码转换和合成方法的这种演变如图5（红色和黄色区域）所示。

在语义约束日益放松的背景下，我们可以将基于llm的代码优化视为这一总体方向的进一步发展：由llm优化的代码甚至可能在语法上不正确，更不用说语义上正确了（如图5的绿色区域所示）。

尽管存在这些正确性挑战，但基于llm的软件工程固有的训练数据池很大，而且llm有表现出突发行为的倾向。这些观察结果结合起来产生了令人惊讶的结果，尽管不能保证是正确的，但可能会以有用的方式极大地改变性能特征。

当然，随着越来越多地允许更宽松的转换集合，以期优化多个非功能属性，同时更依赖于测试的能力，以提供功能的忠实性保证。测试对于检查那些非功能属性中的回归也至关重要，这些属性不是改进过程的目标。因此，一般的软件测试（特别是自动化的高覆盖率测试生成）将变得更加重要。

\subsection{克隆检测和复用}

以前有很多关于托管软件重用的工作[184]，为了提取价值和避免重复，也使用llm解决了一个主题[185]。软件通常包含大量克隆，这是由临时重用产生的，导致在自动克隆检测方面进行了大量工作[186]。基于模糊的微调llm也已应用于此主题[187]。

\subsection{重构}

重构代码时，我们通常希望其行为保持不变。这对于自动化方法特别有吸引力（例如基于搜索的重构[188]），因为这意味着我们可以简单地依赖自动化回归Oracle。这种“免费自动化oracle”的优势非常重要，也适用于基于llm的重构。

Poldrack等人[75]表明，对现有代码进行GPT-4重构可以显著提高代码质量结构指标，如Halstead[189]和McCabe[190]复杂性。Noever和Williams[83]强调了AI驱动的代码助手在重构遗留代码和简化高价值存储库的解释或功能方面的价值。

\subsection{维护和演化中的开放性问题}

由于许多软件维护和演化的子领域都与现有的遗留系统源代码有关，可以预见LLMs的应用将迅速增长。本节概述了这一新兴研究子领域中存在的一些开放问题。

\subsubsection{性能改进中的开放问题}

在开发基于llm的技术以自动发现性能改进方面还需要做更多的工作。与遗传改进一样，这些不需要仅仅局限于执行时间，还可以考虑其他非功能属性，如功耗[191]–[193]和内存占用[194]，以及多目标非功能属性集之间的权衡[195]。我们期待在遗传改进风格的基于llm的代码优化技术上开展更多工作，有可能取得许多重大进展和突破。

\subsubsection{重构中的开放性问题}

根据定义，重构不会改变语义，因此基于llm的重构可以依赖于自动回归Oracle。因此，在基于llm的重构方面还没有更多的工作，这令人惊讶。在这一小节中，我们将概述可能的方向。

三十年来，设计模式在实际软件工程中发挥了关键作用[196]。llm可以帮助工程师重构现有代码以使用设计模式，同时提供对开发人员友好的解释和文档。

每当出现新技术时，重构也是必要的。例如，当API更新或新的API可用时。尽管它们可以（有时是自动的[197]）修复，但API滥用仍然是软件工程bug的常见来源。由于自动化回归Oracle的存在，自动化新API的重构过程比其他代码转换更具挑战性。

最后，llm的少样本学习能力可以实现更多的定制重构。基于llm的重构研究主要集中在全局重构上。然而，程序员通常有特定于项目的重构需求。高达三分之一的软件工程工作花费在大量重复的、乏味的、有潜在错误倾向的重构活动上，以实现这些特定于项目的重构需求。llm的少次学习潜力可能会自动从特定示例中泛化，自动化我们所谓的“定制”重构。需要做更多的工作来开发可靠的少样本学习的定制重构技术。

\section{文档生成}

基于llm的软件工程的大部分工作都集中在代码的生成上，但基于llm的文档生成也有相当大的潜力。

Sun等人[198]探索了ChatGPT在Python代码摘要方面的表现。他们使用了CSN-Python，并将ChatGPT与NCS、CodeBERT和Code5进行了比较。他们采用了三个广泛使用的指标：BLEU、METEOR和ROUGE-L。实验结果表明，ChatGPT的BLEU和ROUGE-L性能明显低于基线模型。

Ahmed等人[66]在GPT-3.5上进行了代码摘要的快速工程。耿等人[199]在两个Java语言数据集Funcom和TLC上进行了实验，使用Codex生成多重意图的评论。Gent等人[200]证明了预训练的llm已经有足够的上下文来从不同的技术角度生成多个不同的代码摘要。

\subsection{文档生成和代码摘要的开放性问题}

许多现有的代码摘要技术是基于检索的：给定的代码使用神经表示以向量格式表示，随后用于检索代码语料库中最相关的文本摘要。

这种方法有一个明显的限制，因为可以生成的摘要集受到训练语料库的约束。LLMs可以在其自然语言处理能力的辅助下，生成不限于训练语料库的自动代码摘要。

虽然这可能会导致更丰富、更语义相关的摘要，本文还注意到，现有的评估指标往往是词汇性的，妨碍了比较和评估llm生成的更丰富摘要的能力[198]。基于ReAct方法的最新进展[95]可能为生成的文档提供更大的保证，即使它无法执行。

\section{软件分析和存储库挖掘}

软件分析是一个成熟的领域，研究如何从现有软件制品中为人类工程师产生洞察力[201]。大量在线公开的软件制品信息刺激了通过挖掘软件库（MSR）[202], [203]获得的科学见解的增长。虽然MSR往往侧重于从这种挖掘中获得科学研究见解，但软件分析往往侧重于组织从自己的存储库分析中获得见解的机会，这也可以有利于AI的可理解性[204]。

迄今为止，在这两种情况下，大部分的数据收集、策展和分析依赖于劳动密集型的人工分析。我们没有发现使用llm来支持此活动的研究。然而，由于许多llm已经采集了这种软件制品数据，并能够提供推理和洞察，因此似乎很自然地期望它们发挥重要作用。

例如，llm可以根据其摄取大量数据的能力，识别出有趣的新的MSR研究问题，包括研究问题和假设之前被证明是研究人员感兴趣的内容。它们也可以帮助追溯软件工程师很难维护的代码[205], [206]。

\section{人机交互}

在人类工程师和软件基础设施之间寻找有效的接口一直是软件工程开发的整个生命周期中反复出现的主题[207], [208]，可以追溯到20世纪60年代该学科的开始[209]。

我们发现了许多有趣的研究问题的证据。例如，Vaithilingam等人[210]报告了24名参与者在理解、编辑和调试副驾驶生成的代码时遇到的困难。同时，Feldt等人[139]提出了基于LLM代理的软件测试设计架构。Liang等人[36]调查了410名实习软件工程师，发现llm被广泛使用以促进低级编程任务，但也有人抵制将llm用于更高层的软件设计活动。Feng等人[211]收集了关于ChatGPT代码生成的316K条推文和3.2K条Reddit帖子，以了解社交媒体对人工智能辅助编码工具的态度。

他们发现，与ChatGPT代码生成相关的主要情绪是恐惧，这种情绪掩盖了快乐和惊喜等其他情绪。Ahmed等人[212]探索了软件架构新手与ChatGPT交互的方式。

\section{软件工程过程}

软件工程关注的不仅是软件产品，还有构建软件产品的过程[213]。之前关于软件助手[207], [214]–[217]的研究显然与基于llm的软件工程研究特别相关，这一主题已经引起一些作者的关注。例如，Ross等人[218]介绍了一个基于llm的程序员助理，并使用42个实例评估了它的部署情况。Tian等人[219]强调了ChatGPT的注意力广度局限性。

\section{软件工程教育}

教师们对确定学生是否依赖llm来构建他们的任务表示担忧[220]，而其他作者则认为llm对教育的长期影响将是有益的[221]。然而，我们目前的重点更局限于llm对软件工程教育领域的具体影响，其中目前的文献侧重于基于llm的教程支持。

例如，Jalil等人[222]探索了ChatGPT在软件测试教育中的机会和问题。Savelka等人[223]分析了在高等教育水平的入门和中级程序设计课程中，LLMs回答多项选择题的三种模式。其他几个作者[82], [83], [224]探索了CodeX生成编程练习和代码解释的能力。他们的普遍发现是，大多数生成的内容是新颖的、明智的且有用的（参见IV-D3部分）。

\section{横切开放研究主题}

许多模式从基于llm的软件工程的萌芽文献中涌现出来。在本节中，我们概述了那些跨越所有软件工程应用的开放研究问题。

\subsection{为SE构建和调优llm}

以前的大多数工作都将llm视为原子组件，重点是将它们纳入更广泛的软件工程工作流中。虽然曾有过调整行为的尝试，但这些尝试往往侧重于快速工程，并有一些微调的例子。

一个更具挑战性但具有潜在影响的问题在于训练和微调模型，特别是针对软件工程任务。Ding等人[225]用执行输入和动态执行轨迹训练一个类似BERT的LLM。他们展示了这种动态信息如何提高模型对下游软件工程预测任务的准确性（高达25％）：漏洞和克隆检测以及覆盖预测（完整执行路径和分支覆盖）。

需要在新形式的llm上做更多的工作，特别是针对软件工程量身定做的，利用软件的独特属性并将其与自然语言区分开来。动态信息是目前大多数工作中缺失的关键区别之一。我们期待下一代特定于SE的llm来解决这个问题。

建立和培训llm的一个重要方面是它们的能源消耗。LLM的功能已与它们的规模相关[226]，导致模型尺寸的快速增长[227], [228]。更大模型的训练和开发可能会对环境产生直接影响[229]。虽然有人认为，模型性能不仅取决于模型大小，还取决于训练数据量[230]，但达到预期性能所需的正确模型大小问题仍然不清楚。

更轻的模型还可能扩大采用范围，从而提高可部署性。最近，诸如低秩自适应（LoRA）[231]和模型量化[232]等技术已显示出潜力，但仍需就特定应用进行经验评估。

\subsection{需要动态自适应提示工程和参数调整}

关于prompt工程的初步工作已经证明了它在显著改进LLMs生成的软件工程制品方面的潜力。然而，正如已经发现的[58]，结果是高度具体的问题，所以一刀切的方法是不现实的。此外，很少有论文报告模型参数设置，但我们知道其中许多，如温度设置，在确定生成的LLM输出的性质方面发挥着至关重要的作用。

作为一个直接的起点，作者必须显著地报告这些参数设置以支持复制。然而，动态自适应提示工程和模型参数调优还需要更多的研究。该研究议程可能会从其他动态自适应任务的参数调优方面的现有工作中获得灵感，例如模糊测试[233]。动态提示优化也可以利用与SBSE[12]相关的技术，将提示优化重新制定为一个多目标计算搜索过程。

\subsection{杂化}

llm在单独使用时很少是最有效的，但作为整个SE过程的一部分可以非常有效。需要更多的工作来理解llm可以安全、高效和有效地驻留的SE工作流的设计模式。我们认为，现有的与生成-测试方法相关的软件工程理论和实践，如自动修复和遗传改进，已经高度适合llm。

我们希望看到更多的工作将llm纳入这些现有的软件工程框架。然而，需要更多的工作来定制和扩展这些框架，以最好地利用基于llm的软件工程提供的机会。

特别是，我们期望看到静态和动态分析工作的快速发展，以便快速进行LLM响应的工程和后处理。我们还希望看到混合软件工程过程，适应持续集成管道以合并llm。

\subsection{控制幻觉}

虽然幻觉被广泛认为是一个问题，正如在本调查中报告的那样，它也可能在应用于软件工程领域时提供好处。LLM的幻觉很少是完全随机的错误反应。相反，由于它们固有的统计特性，它们应该被更好地描述为“合理的未来”。在正确的背景下，这可能经常使它们有用。

幻觉可以被重新利用，为软件增强提供潜在的有用建议。例如，当产生测试用例的幻觉时，LLM可能会被重新用于建议新特征，而幻觉的代码摘要可能表明潜在的（人类）代码误解；如果LLM“误解”了代码，人类难道不会也误解它吗？当LLM对一个不存在的API产生幻觉时，它可能会被重新用作一种建议重构以简化或扩展现有API的方法。我们还需要做更多的工作来开发这种积极的潜力，并利用幻觉来改进软件。

\subsection{稳健、可靠、稳定的评估}

Hort等人[234]对293篇关于代码生成的llm论文进行了审查，以确定是否提供了充分的信息支持复制。他们发现，只有33％的人共享源代码，27％的人共享经过训练的人工制品。他们还从能量消耗的角度评估了这些论文，分析了独立研究人员在训练过程中评估能量消耗的可能性。他们报告说，大约38％（79篇涉及模型训练的出版物中的30篇）共享了足够的信息来估计训练期间的能量消耗。

进一步的证据表明，在基于llm的软件工程文献中，可能存在一个日益增长的科学评估质量问题，例如Wang等人的基于llm的测试调查[98]。他们的调查过滤了初始论文池，以删除那些不满足标准评估质量约束的论文。这些限制要求论文包含清晰、可重复的评估方法，并提供衡量有效性的控制或基线。这个过滤标准删除了90％以上最初符合关键词搜索标准的论文。

这些对文献的分析表明，显然，需要更多的工作来为基于llm的软件工程这一新兴学科建立坚实的科学基础。这种基础可以借鉴一般经验软件工程的现有基础，更具体地说，基于人工智能的软件工程，如SBSE（其中有自然的相似性[105], [235]）。

然而，llm有自己独特的属性，例如提供解释的能力，这将需要特定领域的理论和经验科学基础。

\subsection{全面测试}

幻觉的问题已经被广泛研究。在软件工程社区和更广泛的计算机科学社区中，它将继续是一个非常有趣的话题。虽然可能会取得巨大的进展，但幻觉的固有风险不太可能完全消除，因为它与LLM技术的特性相关，就像人类智能一样。幸运的是，60多年来，软件工程师已经开发了健壮的自动化验证和测试技术，有助于减少人为错误的影响。我们预计这些技术也将延续到人工智能的错误中。

\subsection{处理较长的文本输入}

llm在大型输入提示上的性能可能是人工智能社区非常感兴趣的主题[236]。这一领域的进步将对软件工程产生重大影响，因为软件系统的规模相当大，而在处理较大的提示时，可能会带来新的机会和挑战。

\subsection{软件工程覆盖较少的子领域}

正如我们的调查显示，软件工程的一些子领域在文献中明显代表性不足；有些人出乎意料地如此。例如，需求工程与设计（III），以及重构（VI-E节）的覆盖面较少。然而，考虑到重构严重依赖于分析的语言形式以及模式的识别和预测，其研究时机已经成熟。


% 书面翻译的参考文献
% 默认使用正文的参考文献样式；
% 如果使用 BibTeX，可以切换为其他兼容 natbib 的 BibTeX 样式。
\bibliographystyle{unsrtnat}
% \bibliographystyle{IEEEtranN}

% 默认使用正文的参考文献 .bib 数据库；
% 如果使用 BibTeX，可以改为指定数据库，如 \bibliography{ref/refs}。
\printbibliography

% 书面翻译对应的原文索引
\begin{translation-index}
  \nocite{fan2023large}
  \bibliographystyle{unsrtnat}
  \printbibliography
\end{translation-index}

\end{translation}
