% !TeX root = ../thuthesis-example.tex

% TODO: papers
% https://github.com/FudanSELab/Agent4SE-Paper-List
% Multi-Programming Language Sandbox for LLMs https://arxiv.org/pdf/22410.23074
% Planning-Driven Programming https://arxiv.org/pdf/2411.14503
% AutoDev https://arxiv.org/pdf/2403.08299


\chapter{相关工作}

近年来，大型语言模型（Large Language Models, LLM）在代码生成领域取得了飞跃式发展。OpenAI 的 Codex 模型（Chen 等人，2021~\cite{Chen2021}）和 GPT-3.5/4 系列（OpenAI，2022--2023~\cite{OpenAI2022}）展示了从自然语言描述自动生成代码的能力，引发了软件开发范式变革的讨论~\cite{arxiv2401}. 2022 年以来，学术界和工业界涌现出许多专注于代码的 LLM，如 Google 的 AlphaCode（Li 等人，2022~\cite{Li2022AlphaCode}）、Meta 的 CodeLlama（Roziere 等人，2023~\cite{Roziere2023}）以及开源社区的 StarCoder（Li 等人，2023~\cite{Li2023StarCoder}）等~\cite{arxiv2401}. 这些模型在函数级别的编程挑战（如 LeetCode、HumanEval）上已经能达到甚至超越人类平均水平~\cite{LLMCodeGraph2024}。然而，将 LLM 真正融入软件工程实践，还面临着上下文理解、交互反馈和流程集成等多方面挑战。本文围绕上述三个方面，对 2022 年后的相关研究工作进行综述，总结构建 \emph{bolt.SE} 这类交互式代码生成开发环境的最新进展。

首先，我们关注 LLM 在复杂代码场景下的上下文理解能力，特别是在大型代码库中的表现，如对跨模块接口、依赖关系和体系结构的感知。接着，我们探讨支持实时反馈与运行预览的 LLM 辅助开发工具的架构与实现，包括近年来出现的 Cursor、Continue、Code Interpreter 等代表性工具。最后，我们综述将 LLM 与现代软件工程实践融合的探索，例如将 LLM 融入测试驱动开发（TDD）、持续集成/持续部署（CI/CD）、API-first 等流程，实现自动化支持与集成的相关研究。本文力求通过文献调研呈现 LLM 辅助编程领域的重要成果和趋势，并总结当前的局限与未来展望。

\section{LLM 代码生成的上下文理解能力}

早期的代码生成模型（如 GitHub Copilot 于 2021 年推出）在 IDE 中为开发者提供自动补全建议，但上下文范围有限。例如，Copilot 只能利用当前打开文件的内容进行补全，对整个项目的全局信息缺乏了解~\cite{DivaCopilot}。而大型语言模型在训练中接触了海量代码语料，具有一定的通用编程知识，但在面对大型代码库时仍存在显著挑战。研究表明，LLM 在独立代码片段上的任务（如 LeetCode 题解）表现出色，但在仓库级别的任务上表现不佳~\cite{LLMCodeGraph2024}。这类任务往往需要模型理解跨文件的依赖关系和项目结构，例如函数/类在不同模块中的接口调用、第三方库依赖，以及整体架构设计等~\cite{LLMCodeGraph2024}。当前主流的 LLM 由于上下文窗口限制，无法一次性处理整个大型代码库，这限制了其对全局语境的把握~\cite{LLMCodeGraph2024}。实践中也观察到，ChatGPT 这类模型难以直接进行涉及多个文件的代码改动（如跨文件的重构），因为模型对整个软件系统的视野有限，缺乏 IDE 级的集成~\cite{ChatGPTUsage2023}。由此可见，如何让 LLM 获得更长跨度的上下文理解能力是代码生成领域的重要课题。

为增强 LLM 对大型代码库的理解，研究者探索了多种方法。一方面，扩大小模型的上下文窗口是直接的途径。例如 Guo 等人（2024）提出的 DeepSeek-Coder 系列模型，通过在项目级代码语料上预训练，并采用填空式（Fill-in-the-Middle）训练策略，将上下文长度扩展到 16K tokens，以更好地适应跨文件依赖的代码补全与生成~\cite{arxiv2401,Guo2024}。DeepSeek-Coder 公开的评测显示，在 HumanEval 等基准上，其 33B 参数模型性能领先于其他开源模型，并接近 OpenAI GPT-3.5 的水平~\cite{arxiv2401}。更长的上下文使模型在处理复杂和超出单文件范围的任务时更加游刃有余。另一方面，利用检索增强的方法为 LLM 提供相关的代码片段和设计信息也是有效策略。例如，Liu 等人（2024）提出 CodeXGraph 框架，将整个代码库解析成图数据库，包含了代码中的结构关系（如调用图、依赖图）。LLM 代理可以通过查询图数据库获取所需的代码片段和依赖关系，从而进行结构感知的代码导航和生成~\cite{LLMCodeGraph2024}。相比简单的相似度检索，图结构能够提高相关上下文检索的准确性和覆盖面，帮助 LLM 理解代码的体系架构~\cite{LLMCodeGraph2024}. 类似地，Jiang 等人（2023）和 Sun 等人（2024）的工作也尝试结合信息检索和分块生成，使 LLM 在生成代码时参考到所需的接口定义和依赖实现~\cite{LLMCodeGraph2024}. 总的来看，通过扩展模型能力（更大的预训练和上下文）以及引入外部知识（检索代码片段、构建知识图谱），LLM 在大型代码库中的上下文理解有所提升。一些研究甚至探索让模型生成中间规划或步骤（类似链式思考），逐步细化生成过程，从而避免一开始处理过多上下文信息~\cite{DivaCopilot}. 例如，开源工具 GPTEngineer 尝试让 LLM 先规划任务分解，再逐步实现各子任务~\cite{DivaCopilot}. 这些进展为 LLM 处理复杂软件项目奠定了基础，但目前完全架构感知的代码生成仍未达理想效果，如何让模型真正"看懂"大型系统的全貌仍是开放问题。

\section{支持实时反馈的交互式开发工具}

为弥合 LLM 生成代码与实际开发环境之间的鸿沟，近年出现了一批交互式 LLM 辅助开发工具。这些工具通常集成在开发者常用的 IDE 或编辑器中，提供从代码建议、自动修改到运行结果预览的闭环体验。下面介绍几种具有代表性的工具及其架构。

\subsection{GitHub Copilot (2021)}
作为早期商用的 AI 对话编程助手，Copilot 以 VS Code 扩展形式出现。它基于 OpenAI Codex 模型，在用户编码时给出行内自动补全建议。Copilot 的架构较为简单：将当前文件上下文和光标位置的内容发送给 LLM，返回可能的续写代码~\cite{DivaCopilot}。然而，尽管 Copilot 显著提升了编码效率，其仅依赖当前文件上下文进行代码补全，导致对初学者而言，理解整个项目结构及编码流程存在一定难度；同时，其缺乏交互式反馈机制与自动调试功能，未能充分支持如 TDD、CI/CD 以及 Agent 协作等现代软件工程实践，这在复杂项目开发中尤为不足。

\subsection{Cursor (2023)}
Cursor 是基于 VS Code 开发的 AI 代码编辑器，深度集成了 LLM 功能，支持行内补全、对话式代码修改以及跨文件重构~\cite{CursorReview}。该工具通过 diff 展示修改建议，使得用户可以直观地了解代码变动。虽然 Cursor 在 IDE 融合了编辑、对话和执行等功能，但其对初学者的使用门槛较高，且在自动化测试、持续集成/部署（CI/CD）以及多 Agent 协作等软件工程流程方面仍处于实验性探索阶段，尚未形成完整的工程实践支持体系。

\subsection{ChatGPT Code Interpreter (2023)}
ChatGPT Code Interpreter 实质上是 ChatGPT 的一个 Python 沙盒扩展，允许用户在对话中生成、执行代码，并上传数据文件以获取运行结果~\cite{FirstBlush2023}。这种“所见即所得”的运行反馈降低了模型幻觉的风险，并突破了文本输入长度限制。然而，其运行环境主要局限于 Python，对于其他编程语言及复杂项目的支持不足，同时也未能整合完整的软件工程流程（如测试驱动开发、持续集成等），在面向企业级应用时存在一定局限性。

\subsection{bolt.new and bolt.diy (2024)}
随着 AI 辅助开发工具的不断演进，StackBlitz 推出的 bolt.new 及其开源版本 bolt.diy 于 2024 年相继问世，为交互式代码生成领域带来了新的突破。\\

bolt.new 作为商业产品，依托 StackBlitz 的 WebContainers 技术，实现了从提示、运行、编辑到部署全流程一体化的开发体验；而 bolt.diy 则在继承 bolt.new 核心功能的同时，以开源模式降低了使用门槛，增强了灵活性，使开发者能够自由选择和集成 OpenAI、Anthropic、Ollama 等多种 LLM~\cite{BoltNew2024, BoltDIY2024}。尽管 bolt.diy 在简化开发环境搭建、快速生成项目原型方面具有明显优势，但目前在支持现代软件工程实践方面仍存在不足——例如对 TDD 测试驱动开发、CI/CD 持续集成部署以及多 Agent 协作等高级功能的支持较为有限。正因如此，本研究项目 bolt.SE 将在 bolt.diy 的基础上，进一步拓展其上下文理解能力和开发协作支持，旨在为使用者提供更系统化、可靠且高效的软件开发工具。

TODO: 表格排版错误
\subsection{工具功能对比}
表~\ref{tab:tools} 对比了部分典型 LLM 辅助开发工具在集成平台、主要功能和反馈机制方面的特性。

\begin{table}[htbp]
\centering
\caption{典型 LLM 辅助开发工具功能对比}
\label{tab:tools}
\begin{tabular}{lllp{7cm}}
\toprule
工具名称 & 集成平台 & 主要功能 & 反馈机制 \\
\midrule
GitHub Copilot (2021) & VS Code 等 IDE 扩展 & 基于当前文件上下文提供单文件代码补全及行内生成建议 & 无实时运行反馈；对全局项目结构理解不足，初学者较难把握整体架构 \\
\addlinespace
Cursor (2023) & 基于 VS Code 衍生的专用编辑器 & 支持对话式代码修改、跨文件重构及差异展示（diff） & 通过对话嵌入反馈修改建议；缺乏成熟的 CI/CD 与 TDD 支持，初学者难以全面掌握项目设计 \\
\addlinespace
ChatGPT Code Interpreter (2023) & ChatGPT Web 界面 & 对话生成代码与 Python 沙盒执行，支持文件上传与运行结果展示 & 提供执行输出和文件交互反馈，但运行环境局限于 Python，整体软件工程流程支持不足 \\
\addlinespace
bolt.new (2024) & 浏览器内 WebContainers & 实现全流程全栈应用生成，支持依赖安装、代码编辑与即时部署预览 & 交互式反馈良好，用户体验稳定；作为商业产品具备较高成熟度 \\
\addlinespace
bolt.diy (2024) & 浏览器内 WebContainers（开源） & 快速原型生成、低门槛入门，支持多 LLM 模型接入 & 开源优势明显，便于社区扩展；但在软件工程实践支持上尚不完善 \\
\bottomrule
\end{tabular}
\end{table}



可以看到，新一代工具正逐步引入实时的验证与反馈环节，使得 LLM 生成的代码能够立即在环境中检验，从而不断改进输出质量。这种人机协作的实时交互为构建 \emph{bolt.SE} 这类智能开发环境提供了技术基础。

\section{LLM 与现代软件工程实践的融合}

除了在编码层面提供帮助，将 LLM 更深入地融入软件工程流程也是近年的研究热点。本文从测试驱动开发、持续集成/交付以及 API 优先开发等方面，探讨 LLM 在现代开发流程中的应用探索。

\subsection{测试驱动开发（TDD）与 LLM}

TDD 提倡先写测试再写实现，以确保代码严格满足需求。Mathews 和 Nagappan（2024）研究了将 TDD 理念用于 AI 代码生成的效果~\cite{Mathews2024TDD}。他们让 LLM 在收到问题描述的同时，也获得对应的单元测试用例，然后再让模型生成实现代码。实验在 HumanEval、MBPP 等基准上进行，对比仅提供描述的基线，结果显示提供测试用例能显著提高生成代码的正确率~\cite{Mathews2024TDD}。具体而言，包含测试上下文时，GPT-4、Code Llama 等模型的通过率提升了几个百分点。这证明了 TDD 范式对 LLM 同样有益：测试用例明确了预期行为，使模型有"靶子"可对照，从而减少模糊理解和瞎猜~\cite{Mathews2024TDD}。这一发现推动了"生成-执行-验证"循环在 AI 辅助编程中的应用。未来，随着 LLM 对编译器、测试框架接口调用能力的增强，我们有望看到更加自动化的 "TDD for AI" 工作流。

\subsection{持续集成与交付（CI/CD）}

将 LLM 嵌入 CI/CD 流水线，可以减轻开发者在代码审查和质量检查方面的负担。已有研究通过挖掘开源项目实践，揭示了 ChatGPT 这类模型在 CI 中的实际用例~\cite{ChatGPTUsage2023}。最常见的是充当 Pull Request 的自动审查助手：在 CI 流程中集成一个 ChatGPT 驱动的 bot，对新提交的代码发表评论，指出潜在 bug 或不佳实现，并给出改进建议~\cite{ChatGPTUsage2023}。这种 AI 审查能在几分钟内提供初步反馈，协助人类审查者发现问题，从而加速代码合并过程~\cite{ChatGPTUsage2023}。研究还发现，ChatGPT 审查通常与传统 lint 工具结合使用，一方面提供风格和覆盖率检查，另一方面给出更高级的代码改进建议~\cite{ChatGPTUsage2023}。此外，LLM 还被用于自动生成 CI 配置和脚本。例如，有开发者让 ChatGPT 编写 GitHub Actions 的配置或 Dockerfile，以快速搭建 CI/CD 流程~\cite{ChatGPTUsage2023}。然而，由于训练数据的时效性和参数固化，模型可能对最新 CI 技术（如最新的 Actions 语法）不了解，生成的脚本可能采用过时的命令，从而导致 CI 失败~\cite{ChatGPTUsage2023}. 审查者反馈"LLM 生成的动作版本已过期"~\cite{ChatGPTUsage2023}，这提示在 CI/CD 场景下需要持续更新或采用可快速微调的专用模型。

\subsection{API 优先开发（API-First）}

现代软件开发强调 API 契约先行，根据接口规范生成实现和测试。典型场景为：给定详细的 API 规范（例如 OpenAPI 文档），让 LLM 生成对应服务的代码骨架或实现。直接将完整的 OpenAPI 描述输入 LLM 往往超过其上下文长度，导致模型遗忘细节或遗漏功能~\cite{DivaCopilot}。为此，有研究采用分而治之的方法，如先让 LLM 阅读 API 说明并输出实现计划，然后逐条接口生成代码，分步完成整个服务~\cite{DivaCopilot}. 最近 Ericsson 公司开展了一项实验性研究，设计了一个自动编排 LLM 推理的原型系统：首先用 GPT 模型对 OpenAPI 规范进行总结和任务拆解，再针对每个接口或模块调用代码生成模型，最后汇总结果组装完整项目~\cite{DivaCopilot,DivaCopilot}. 专业开发者对生成代码的评估表明，这种方法能产出相当比例正确的样板代码，大大减少了手工编写重复样板的工作量，但生成的代码通常仍需人工审查修改，以确保满足性能和安全等要求。
